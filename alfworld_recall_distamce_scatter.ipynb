{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837169a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orjson\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "from utils.analysis_files.analysis import load_all_data\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "from utils.analysis_files.analysis_wcr import cal_weighted_corrected_rate\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba065a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(line):\n",
    "    if not line.strip():\n",
    "        return None\n",
    "    item = orjson.loads(line)\n",
    "    # item.pop(\"rollout_trajectories\", None)\n",
    "    return item\n",
    "\n",
    "def load_jsonl_parallel(data_dir, n_workers=32):\n",
    "    with open(data_dir, \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    with mp.Pool(n_workers) as pool:\n",
    "        data = [x for x in pool.map(process_line, lines) if x is not None]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def find_jsonl_file(directory):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.jsonl'):\n",
    "            return os.path.join(directory, file)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_dir_base_env_state = \"res/alfworld/Llama3-70B_user_assistant_format_20251206\"\n",
    "data_dir_base_env_state = \"res/alfworld/Llama-3.3-70B_user_assistant_format_20251221_001\"\n",
    "\n",
    "\n",
    "# df_no_state = load_all_data(load_jsonl_parallel(find_jsonl_file(data_dir_base_no_state), n_workers=128))\n",
    "df_env_state = load_all_data(load_jsonl_parallel(find_jsonl_file(data_dir_base_env_state), n_workers=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_id(row):\n",
    "    if row['seed'] is not None and row['seed'] != 'none':\n",
    "        return row['seed']\n",
    "    else:\n",
    "        return row['query']\n",
    "\n",
    "# Add unique identifier column for both datasets\n",
    "# df_no_state['unique_id'] = df_no_state.apply(get_unique_id, axis=1)\n",
    "df_env_state['unique_id'] = df_env_state.apply(get_unique_id, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79088fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate average recall distance for each sample\n",
    "def calculate_obj_recall_distance(df, sample_idx, traj_idx):\n",
    "    \"\"\"Calculate obj recall distance for a single trajectory\"\"\"\n",
    "    traj_df = df[(df['sample_idx'] == sample_idx) & (df['traj_idx'] == traj_idx)].copy()\n",
    "    \n",
    "    # Get task information\n",
    "    from utils.analysis_files.alfworld_mem_recall import extract_objects_and_locations\n",
    "    task_type, _, _, task_objects, _ = extract_objects_and_locations(traj_df.iloc[0][\"query\"])\n",
    "    \n",
    "    task_obj_set = set([obj.lower() for obj in task_objects])\n",
    "    \n",
    "    # Store the last step where each task obj appeared\n",
    "    obj_last_seen = {}\n",
    "    distances = []\n",
    "    \n",
    "    for step_idx in sorted(traj_df['step_idx'].unique()):\n",
    "        if step_idx == 0:\n",
    "            continue\n",
    "            \n",
    "        step_data = traj_df[traj_df['step_idx'] == step_idx]\n",
    "        \n",
    "        # Skip invalid action\n",
    "        if not step_data['action_is_valid'].iloc[0]:\n",
    "            continue\n",
    "        \n",
    "        # Get objects in current obs\n",
    "        obs = step_data[\"observation\"].values[0]\n",
    "        _, _, obs_objects, _, _ = extract_objects_and_locations(obs)\n",
    "        \n",
    "        # Update last appearance position for each object\n",
    "        for obj_tuple in obs_objects:\n",
    "            obj_name = obj_tuple[0].lower()\n",
    "            obj_last_seen[obj_name] = step_idx\n",
    "        \n",
    "        # Get objects in current action\n",
    "        action = step_data[\"action\"].values[0]\n",
    "        _, _, action_objects, _, _ = extract_objects_and_locations(action)\n",
    "        \n",
    "        # Check if objects in action hit task obj\n",
    "        for action_obj in action_objects:\n",
    "            action_obj_name = action_obj[0].lower()\n",
    "            if action_obj_name in task_obj_set:\n",
    "                # If this task obj appeared before, calculate distance\n",
    "                if action_obj_name in obj_last_seen:\n",
    "                    distance = step_idx - obj_last_seen[action_obj_name]\n",
    "                    distances.append(distance)\n",
    "    \n",
    "    # Return average recall distance for this trajectory\n",
    "    if distances:\n",
    "        return np.mean(distances)\n",
    "    else:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf015971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate recall distance for all trajectories\n",
    "from utils.analysis_files.alfworld_mem_recall import extract_objects_and_locations\n",
    "\n",
    "recall_distances = []\n",
    "for (sample_idx, traj_idx), group in df_env_state.groupby(['sample_idx', 'traj_idx']):\n",
    "    dist = calculate_obj_recall_distance(df_env_state, sample_idx, traj_idx)\n",
    "    recall_distances.append({\n",
    "        'sample_idx': sample_idx,\n",
    "        'traj_idx': traj_idx,\n",
    "        'obj_recall_distance': dist\n",
    "    })\n",
    "\n",
    "recall_distance_df = pd.DataFrame(recall_distances)\n",
    "\n",
    "# Calculate average recall distance for each sample\n",
    "sample_avg_distance = recall_distance_df.groupby('sample_idx')['obj_recall_distance'].mean().reset_index()\n",
    "sample_avg_distance.columns = ['sample_idx', 'avg_obj_recall_distance']\n",
    "\n",
    "# 2. Merge to merged_df\n",
    "# First need to map sample_idx to unique_id\n",
    "sample_id_mapping = df_env_state[['sample_idx', 'unique_id','avg_accuracy']].drop_duplicates()\n",
    "sample_avg_distance = sample_avg_distance.merge(sample_id_mapping, on='sample_idx', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Plot scatter plot: avg_obj_recall_distance vs avg_accuracy (env-state only)\n",
    "plt.figure(figsize=(8,5), dpi=120)\n",
    "p = sns.scatterplot(\n",
    "    data=sample_avg_distance.dropna(subset=['avg_obj_recall_distance','avg_accuracy']),\n",
    "    x='avg_obj_recall_distance', y='avg_accuracy', s=60, alpha=0.7\n",
    ")\n",
    "p.set_title(\"Env-state: Average Object Recall Distance vs Avg Accuracy\", fontsize=14)\n",
    "p.set_xlabel(\"Average Object Recall Distance (per sample)\", fontsize=12)\n",
    "p.set_ylabel(\"Average Accuracy (env_state)\", fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6) Output simple statistics and correlation coefficient\n",
    "valid = sample_avg_distance.dropna(subset=['avg_obj_recall_distance','avg_accuracy'])\n",
    "print(f\"Sample count: {len(valid)}  Average recall distance: {valid['avg_obj_recall_distance'].mean():.3f}\")\n",
    "if len(valid) >= 2:\n",
    "    corr = valid[['avg_obj_recall_distance','avg_accuracy']].corr().iloc[0,1]\n",
    "    print(f\"Pearson correlation coefficient between recall distance and avg_accuracy: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66808285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter plot and box plot of success vs recall_distance for each traj\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=120)\n",
    "\n",
    "# Prepare data: add success information for each traj\n",
    "traj_success = df_env_state.groupby(['sample_idx', 'traj_idx'])['success'].first().reset_index()\n",
    "recall_distance_with_success = recall_distance_df.merge(traj_success, on=['sample_idx', 'traj_idx'], how='left')\n",
    "\n",
    "# Remove NaN values\n",
    "valid_data = recall_distance_with_success.dropna(subset=['obj_recall_distance'])\n",
    "\n",
    "# Plot grouped by success status\n",
    "success_data = valid_data[valid_data['success'] == True]\n",
    "fail_data = valid_data[valid_data['success'] == False]\n",
    "\n",
    "# Plot scatter plot\n",
    "ax.scatter(fail_data['obj_recall_distance'], \n",
    "           [0] * len(fail_data), \n",
    "           alpha=0.6, s=80, c='red', label='Failed', marker='x')\n",
    "ax.scatter(success_data['obj_recall_distance'], \n",
    "           [1] * len(success_data), \n",
    "           alpha=0.6, s=80, c='green', label='Success', marker='o')\n",
    "\n",
    "ax.set_xlabel('Object Recall Distance', fontsize=14)\n",
    "ax.set_ylabel('Trajectory Success', fontsize=14)\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels(['Failed', 'Success'])\n",
    "ax.set_title('Trajectory Success vs. Object Recall Distance', fontsize=16)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, axis='x', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Output statistics\n",
    "print(\"\\nRecall distance statistics by Success status:\")\n",
    "print(f\"Success trajectory count: {len(success_data)}, Average recall distance: {success_data['obj_recall_distance'].mean():.2f}\")\n",
    "print(f\"Failed trajectory count: {len(fail_data)}, Average recall distance: {fail_data['obj_recall_distance'].mean():.2f}\")\n",
    "\n",
    "# Use box plot to show clearer comparison\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=120)\n",
    "sns.boxplot(data=valid_data, x='success', y='obj_recall_distance', ax=ax)\n",
    "ax.set_xlabel('Trajectory Success', fontsize=14)\n",
    "ax.set_ylabel('Object Recall Distance', fontsize=14)\n",
    "ax.set_xticklabels(['Failed', 'Success'])\n",
    "ax.set_title('Object Recall Distance Distribution by Success Status', fontsize=16)\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('recall_distance_boxplot_by_success.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Perform statistical test\n",
    "from scipy import stats\n",
    "if len(success_data) > 0 and len(fail_data) > 0:\n",
    "    t_stat, p_value = stats.ttest_ind(\n",
    "        success_data['obj_recall_distance'].dropna(), \n",
    "        fail_data['obj_recall_distance'].dropna()\n",
    "    )\n",
    "    print(f\"\\nt-test result: t-statistic={t_stat:.3f}, p-value={p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"Conclusion: There is a significant difference in recall distance between Success and Failed trajectories\")\n",
    "    else:\n",
    "        print(\"Conclusion: There is no significant difference in recall distance between Success and Failed trajectories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda49ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save box plot data as JSON format\n",
    "import json\n",
    "# Prepare data to save\n",
    "exp_name = data_dir_base_env_state.split('/')[-1]\n",
    "boxplot_data = {\n",
    "    'metadata': {\n",
    "        'exp_name': exp_name,\n",
    "        'total_trajectories': len(valid_data),\n",
    "        'success_count': len(success_data),\n",
    "        'failed_count': len(fail_data),\n",
    "        'success_mean_recall_distance': float(success_data['obj_recall_distance'].mean()) if len(success_data) > 0 else None,\n",
    "        'failed_mean_recall_distance': float(fail_data['obj_recall_distance'].mean()) if len(fail_data) > 0 else None,\n",
    "    },\n",
    "    'trajectories': []\n",
    "}\n",
    "# Add data for each trajectory\n",
    "for _, row in valid_data.iterrows():\n",
    "    boxplot_data['trajectories'].append({\n",
    "        'sample_idx': int(row['sample_idx']),\n",
    "        'traj_idx': int(row['traj_idx']),\n",
    "        'success': bool(row['success']),\n",
    "        'obj_recall_distance': float(row['obj_recall_distance'])\n",
    "    })\n",
    "# Save as JSON file\n",
    "with open(f'recall_distance_boxplot_data_{exp_name}.json', 'w') as f:\n",
    "    json.dump(boxplot_data, f, indent=2)\n",
    "print(f\"\\nâœ“ Box plot data saved to recall_distance_boxplot_data_{exp_name}.json\")\n",
    "print(f\"  - Total trajectories: {len(valid_data)}\")\n",
    "print(f\"  - Success trajectories: {len(success_data)}, Failed trajectories: {len(fail_data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
