{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orjson\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results(base_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load result.json files from all experiment subdirectories under the specified base directory,\n",
    "    and merge them into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    all_results_data = []\n",
    "\n",
    "    if not os.path.isdir(base_dir):\n",
    "        print(f\"Error: Base directory '{base_dir}' does not exist.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Iterate through all entries in base directory\n",
    "    for exp_folder_name in os.listdir(base_dir):\n",
    "        exp_path = os.path.join(base_dir, exp_folder_name)\n",
    "\n",
    "        # Ensure it is a directory\n",
    "        if os.path.isdir(exp_path):\n",
    "            result_file_path = os.path.join(exp_path, \"result.json\")\n",
    "\n",
    "            # Check if result.json exists\n",
    "            if os.path.exists(result_file_path):\n",
    "                try:\n",
    "                    with open(result_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        result_data = json.load(f)\n",
    "                        # Add experiment folder name as a column for identification\n",
    "                        result_data[\"experiment\"] = exp_folder_name\n",
    "                        all_results_data.append(result_data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Warning: Unable to parse JSON in file {result_file_path}.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Error reading file {result_file_path}: {e}\")\n",
    "\n",
    "    if not all_results_data:\n",
    "        print(\"No 'result.json' files found or processed.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    results_df = pd.DataFrame(all_results_data)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b96026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_area_under_curve(df: pd.DataFrame, start:int, end:int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the area under the curve (AUC) for specified metrics, subtracting the area below the minimum value in the interval.\n",
    "    Also update pass_k and pass_mean to the accuracy at the end step.\n",
    "    \n",
    "    Parameters:\n",
    "        df: DataFrame containing experiment results\n",
    "        start: Starting turn number\n",
    "        end: Ending turn number\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with added AUC and end accuracy columns\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    passk_auc = []\n",
    "    pass1_auc = []\n",
    "    passk_end_values = []\n",
    "    pass1_end_values = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        passk_dict = row['passk_at_T']\n",
    "        pass1_dict = row['pass1_at_T']\n",
    "        \n",
    "        def extract_series(data_dict):\n",
    "            values = []\n",
    "            last_value = 0.0  # Initialize value from previous round\n",
    "            for t in range(start, end + 1):\n",
    "                key = str(t)\n",
    "                if key in data_dict:\n",
    "                    last_value = data_dict[key]  # Update value from previous round\n",
    "                    values.append(last_value)\n",
    "                else:\n",
    "                    values.append(last_value)  # Use value from previous round\n",
    "            return values\n",
    "        \n",
    "        passk_values = extract_series(passk_dict)\n",
    "        pass1_values = extract_series(pass1_dict)\n",
    "        \n",
    "        min_passk = min(passk_values)\n",
    "        adjusted_passk = [value - min_passk for value in passk_values]\n",
    "        passk_auc.append(max(np.trapz(adjusted_passk, dx=1), 0.0))\n",
    "        \n",
    "        min_pass1 = min(pass1_values)\n",
    "        adjusted_pass1 = [value - min_pass1 for value in pass1_values]\n",
    "        pass1_auc.append(max(np.trapz(adjusted_pass1, dx=1), 0.0))\n",
    "        \n",
    "        def get_value_at_step(data_dict):\n",
    "            end_key = str(end)\n",
    "            if end_key in data_dict:\n",
    "                return data_dict[end_key]\n",
    "            if not data_dict:\n",
    "                return np.nan\n",
    "            numeric_keys = sorted(int(k) for k in data_dict.keys())\n",
    "            lower_keys = [k for k in numeric_keys if k <= end]\n",
    "            if lower_keys:\n",
    "                return data_dict[str(lower_keys[-1])]\n",
    "            higher_keys = [k for k in numeric_keys if k > end]\n",
    "            if higher_keys:\n",
    "                return data_dict[str(higher_keys[0])]\n",
    "            return np.nan\n",
    "        \n",
    "        passk_end_values.append(get_value_at_step(passk_dict))\n",
    "        pass1_end_values.append(get_value_at_step(pass1_dict))\n",
    "    \n",
    "    span = max(end - start, 1)  # Avoid division by zero\n",
    "    df['passk_auc'] = np.array(passk_auc, dtype=float) / span\n",
    "    df['pass1_auc'] = np.array(pass1_auc, dtype=float) / span\n",
    "    df['pass_k'] = passk_end_values\n",
    "    df['pass_mean'] = pass1_end_values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exp_base_dir = \"res/frozen_lake\"\n",
    "\n",
    "# Load all experiment results into DataFrame\n",
    "df_experiments = load_all_results(all_exp_base_dir)\n",
    "\n",
    "# Display first few rows of DataFrame for inspection\n",
    "if not df_experiments.empty:\n",
    "    print(f\"Successfully loaded results from {len(df_experiments)} experiments.\")\n",
    "    # display(df_experiments.head())\n",
    "else:\n",
    "    print(\"Failed to load any experiment results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51231d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_criteria = {\n",
    "    'model_name': 'Qwen3-4B',\n",
    "    \"enable_thinking\": False,\n",
    "    \"state\": \"env\",\n",
    "    'chat_format': 'user_assistant_format_part',\n",
    "    # \"alfworld_mode\": \"eval_in_distribution\",\n",
    "    'history_has_cot': True,\n",
    "    \"stop_by_self\": False,\n",
    "    # \"history_window_size\": 3,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1\n",
    "end = 20\n",
    "# --- 2. Filter DataFrame based on criteria ---\n",
    "if selection_criteria:\n",
    "    # Start from base DataFrame\n",
    "    query_str = \" & \".join(\n",
    "        [f\"`{k}` == {repr(v)}\" for k, v in selection_criteria.items()]\n",
    "    )\n",
    "    selected_df = df_experiments.query(query_str)\n",
    "else:\n",
    "    # If no filter criteria, select all experiments\n",
    "    selected_df = df_experiments\n",
    "selected_df = cal_area_under_curve(selected_df, start=start, end=end)\n",
    "sort_list = ['history_window_size', 'pass_k', 'model_name']\n",
    "selected_df = selected_df.sort_values(by=sort_list, ascending=[True, True, True]).reset_index(drop=True)\n",
    "print(f\"Found {len(selected_df)} experiments matching the filter criteria.\")\n",
    "display(\n",
    "    selected_df[[\"experiment\",'model_name',\"history_window_size\",\"pass1_auc\", \"pass_mean\"]]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
