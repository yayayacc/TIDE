{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837169a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orjson\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "from utils.analysis_files.analysis import load_all_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.analysis_files.analysis import load_all_data, identify_error_atomic_actions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba065a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(line):\n",
    "    if not line.strip():\n",
    "        return None\n",
    "    item = orjson.loads(line)\n",
    "    # item.pop(\"rollout_trajectories\", None)\n",
    "    return item\n",
    "\n",
    "def load_jsonl_parallel(data_dir, n_workers=32):\n",
    "    with open(data_dir, \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    with mp.Pool(n_workers) as pool:\n",
    "        data = [x for x in pool.map(process_line, lines) if x is not None]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def find_jsonl_file(directory):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.jsonl'):\n",
    "            return os.path.join(directory, file)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854983c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_exp_data(base_dir: str, selection_criteria: dict = None):\n",
    "    \"\"\"\n",
    "    Load data from all experiment subdirectories under the specified base directory,\n",
    "    filter experiments according to selection_criteria,\n",
    "    and return looped atomic action length statistics for each experiment\n",
    "    \"\"\"\n",
    "    from utils.analysis_files.analysis import get_config, get_config_label\n",
    "    \n",
    "    all_exp_results = []\n",
    "    \n",
    "    if not os.path.isdir(base_dir):\n",
    "        print(f\"Error: Base directory '{base_dir}' does not exist.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Iterate through all experiment folders\n",
    "    for exp_folder_name in os.listdir(base_dir):\n",
    "        exp_path = os.path.join(base_dir, exp_folder_name)\n",
    "        \n",
    "        if not os.path.isdir(exp_path):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Read configuration\n",
    "            config_data = get_config(exp_path)\n",
    "            \n",
    "            # Filter according to selection_criteria\n",
    "            if selection_criteria:\n",
    "                match = all(\n",
    "                    config_data.get(k) == v \n",
    "                    for k, v in selection_criteria.items()\n",
    "                )\n",
    "                if not match:\n",
    "                    continue\n",
    "            \n",
    "            # Find jsonl file\n",
    "            jsonl_path = find_jsonl_file(exp_path)\n",
    "            if not jsonl_path:\n",
    "                print(f\"Warning: No .jsonl file found in {exp_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Load data\n",
    "            print(f\"Loading data from: {exp_folder_name}\")\n",
    "            raw_data = load_jsonl_parallel(jsonl_path, n_workers=32)\n",
    "            df = load_all_data(raw_data)\n",
    "            \n",
    "            # Calculate looped atomic action length statistics\n",
    "            df_sorted = df.sort_values(['sample_idx', 'traj_idx', 'step_idx']).reset_index(drop=True)\n",
    "            \n",
    "            result_list = []\n",
    "            for (sample_idx, traj_idx), group in df_sorted.groupby(['sample_idx', 'traj_idx']):\n",
    "                group = group.reset_index(drop=True)\n",
    "                marks = identify_error_atomic_actions(group)\n",
    "                marks['sample_idx'] = sample_idx\n",
    "                marks['traj_idx'] = traj_idx\n",
    "                marks['step_idx'] = group['step_idx'].values\n",
    "                result_list.append(marks)\n",
    "            \n",
    "            marks_df = pd.concat(result_list, ignore_index=True)\n",
    "            df_sorted = df_sorted.merge(\n",
    "                marks_df, \n",
    "                on=['sample_idx', 'traj_idx', 'step_idx'], \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Count looped atomic action lengths\n",
    "            looped_ids = df_sorted[df_sorted['is_looped'] == True][\n",
    "                ['sample_idx', 'traj_idx', 'error_atomic_id']\n",
    "            ].drop_duplicates()\n",
    "            \n",
    "            atomic_action_lengths = []\n",
    "            for _, row in looped_ids.iterrows():\n",
    "                sample_idx = row['sample_idx']\n",
    "                traj_idx = row['traj_idx']\n",
    "                error_id = row['error_atomic_id']\n",
    "                \n",
    "                group = df_sorted[\n",
    "                    (df_sorted['sample_idx'] == sample_idx) & \n",
    "                    (df_sorted['traj_idx'] == traj_idx) & \n",
    "                    (df_sorted['error_atomic_id'] == error_id)\n",
    "                ]\n",
    "                \n",
    "                length = len(group)\n",
    "                atomic_action_lengths.append({\n",
    "                    'sample_idx': sample_idx,\n",
    "                    'traj_idx': traj_idx,\n",
    "                    'error_atomic_id': error_id,\n",
    "                    'length': length\n",
    "                })\n",
    "            \n",
    "            atomic_lengths_df = pd.DataFrame(atomic_action_lengths)\n",
    "            \n",
    "            # Calculate length distribution ratios\n",
    "            if len(atomic_lengths_df) > 0:\n",
    "                length_ratios = atomic_lengths_df['length'].value_counts(normalize=True).sort_index()\n",
    "                length_ratios_dict = length_ratios.to_dict()\n",
    "            else:\n",
    "                length_ratios_dict = {}\n",
    "            \n",
    "            # Generate experiment label\n",
    "            exclude_keys = set(selection_criteria.keys()) if selection_criteria else set()\n",
    "            exp_label = get_config_label(pd.Series(config_data), exclude_keys)\n",
    "            \n",
    "            # Save result\n",
    "            result = {\n",
    "                'experiment': exp_folder_name,\n",
    "                'label': exp_label,\n",
    "                'length_ratios': length_ratios_dict,\n",
    "                'total_looped_actions': len(atomic_lengths_df),\n",
    "                **config_data\n",
    "            }\n",
    "            all_exp_results.append(result)\n",
    "            \n",
    "            print(f\"  - Found {len(atomic_lengths_df)} looped atomic actions\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {exp_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_exp_results:\n",
    "        print(\"No experiments found matching the criteria.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    results_df = pd.DataFrame(all_exp_results)\n",
    "    print(f\"\\nSuccessfully loaded {len(results_df)} experiments.\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac127fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_criteria = {\n",
    "    # 'model_name': 'Qwen3-30B-A3B',\n",
    "    # \"enable_thinking\": False,\n",
    "    \"state\": \"env\",\n",
    "    'chat_format': 'user_assistant_format',\n",
    "    # \"alfworld_mode\": \"eval_in_distribution\",\n",
    "    'history_has_cot': True,\n",
    "    \"stop_by_self\": False,\n",
    "    # \"offer_feedback\": True,\n",
    "    # \"prompt_example\": \"fewshot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all experiment data\n",
    "all_exp_base_dir = \"./res/blocksworld\"\n",
    "data_all_experiments = load_all_exp_data(all_exp_base_dir, selection_criteria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_all_experiments.empty:\n",
    "    stats_results = []\n",
    "    \n",
    "    for idx, row in data_all_experiments.iterrows():\n",
    "        length_ratios = row['length_ratios']\n",
    "        \n",
    "        if length_ratios:\n",
    "            # Calculate ratio for len=1\n",
    "            ratio_len_1 = length_ratios.get(1, 0)\n",
    "            \n",
    "            # Calculate ratio for len>1\n",
    "            ratio_len_gt_1 = sum(ratio for length, ratio in length_ratios.items() if length > 1)\n",
    "            \n",
    "            stats_results.append({\n",
    "                'experiment': row['experiment'],\n",
    "                \"enable_thinking\": row[\"enable_thinking\"],\n",
    "                \"chat_format\": row[\"chat_format\"],\n",
    "                \"history_has_cot\": row[\"history_has_cot\"],\n",
    "                \"state\": row[\"state\"],\n",
    "                'label': row['label'],\n",
    "                'model_name': row.get('model_name', 'Unknown'),\n",
    "                'total_looped_actions': row['total_looped_actions'],\n",
    "                'ratio_len_1': ratio_len_1,\n",
    "                'ratio_len_gt_1': ratio_len_gt_1\n",
    "            })\n",
    "        else:\n",
    "            stats_results.append({\n",
    "                'experiment': row['experiment'],\n",
    "                \"enable_thinking\": row[\"enable_thinking\"],\n",
    "                \"chat_format\": row[\"chat_format\"],\n",
    "                \"history_has_cot\": row[\"history_has_cot\"],\n",
    "                \"state\": row[\"state\"],\n",
    "                'label': row['label'],\n",
    "                'model_name': row.get('model_name', 'Unknown'),\n",
    "                'total_looped_actions': 0,\n",
    "                'ratio_len_1': 0,\n",
    "                'ratio_len_gt_1': 0\n",
    "            })\n",
    "    \n",
    "    stats_df = pd.DataFrame(stats_results)\n",
    "    \n",
    "    # Define model order\n",
    "    model_order = [\n",
    "        'Qwen3-4B',\n",
    "        'Qwen3-30B-A3B',\n",
    "        'Llama3-8B',\n",
    "        'Llama3-70B',\n",
    "        'Glm-9B-Chat',\n",
    "        'Glm4-9B-Chat',\n",
    "        \"GLM-4-32B-0414\",\n",
    "        'Mistral-7B-Instruct-v0.3',\n",
    "        'Ministral-3-14B-Instruct-2512',\n",
    "        'phi-4',\n",
    "        'deepseek-v3',\n",
    "        'deepseek-v3.2',\n",
    "        'gemini-2.5-flash',\n",
    "        'gemini-2.5-flash-nothinking',\n",
    "        'Phi-4-reasoning',\n",
    "        'gpt-oss-120b',\n",
    "        'deepseek-r1',\n",
    "        'gemini-2.5-pro',\n",
    "    ]\n",
    "    \n",
    "    # Create model sort mapping\n",
    "    model_order_map = {model: idx for idx, model in enumerate(model_order)}\n",
    "    stats_df['model_sort_order'] = stats_df['model_name'].map(\n",
    "        lambda x: model_order_map.get(x, 999)  # Models not in list are placed last\n",
    "    )\n",
    "    sort_list = ['enable_thinking','model_sort_order','chat_format','history_has_cot',\"state\"]\n",
    "    # Sort by model order\n",
    "    stats_df = stats_df.sort_values(by=sort_list, ascending=[True, True, True, True, False]).reset_index(drop=True)\n",
    "    \n",
    "    # Delete auxiliary sort column\n",
    "    # stats_df = stats_df.drop('model_sort_order', axis=1)\n",
    "    \n",
    "    display(\n",
    "    stats_df[[\"model_name\",\"total_looped_actions\",\"ratio_len_1\",\"ratio_len_gt_1\"]]\n",
    ")\n",
    "else:\n",
    "    print(\"No experiments to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Len1\\tLen>1\\t\")\n",
    "for idx, row in stats_df.iterrows():\n",
    "    Len1_ratio = row[\"ratio_len_1\"]\n",
    "    LenGT1_ratio = row[\"ratio_len_gt_1\"]\n",
    "    print(f\"{Len1_ratio*100:.1f}\\t{LenGT1_ratio*100:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line chart for all experiments\n",
    "if not data_all_experiments.empty:\n",
    "    # Find all length values that appear in all experiments\n",
    "    export_data = {\n",
    "        'metadata': {\n",
    "            'total_experiments': len(data_all_experiments),\n",
    "            'selection_criteria': selection_criteria\n",
    "        },\n",
    "        'experiments': []\n",
    "    }\n",
    "    all_lengths = set()\n",
    "    for idx, row in data_all_experiments.iterrows():\n",
    "        length_ratios = row['length_ratios']\n",
    "        if length_ratios:\n",
    "            all_lengths.update(length_ratios.keys())\n",
    "    \n",
    "    # If there is data, sort by length\n",
    "    if all_lengths:\n",
    "        all_lengths = sorted(all_lengths)\n",
    "        \n",
    "        plt.figure(figsize=(12, 7))\n",
    "        colors = sns.color_palette(\"tab10\", n_colors=len(data_all_experiments))\n",
    "        \n",
    "        for idx, row in data_all_experiments.iterrows():\n",
    "            length_ratios = row['length_ratios']\n",
    "            \n",
    "            # Create data for all lengths, set missing lengths to 0\n",
    "            x_data = all_lengths\n",
    "            y_data = [length_ratios.get(length, 0) for length in all_lengths]\n",
    "            \n",
    "            export_data['experiments'].append({\n",
    "                'experiment_name': row['experiment'],\n",
    "                'label': row['label'],\n",
    "                'x_data': all_lengths,\n",
    "                'y_data': y_data\n",
    "            })\n",
    "            plt.plot(\n",
    "                x_data, \n",
    "                y_data, \n",
    "                marker='o', \n",
    "                linewidth=2, \n",
    "                markersize=6,\n",
    "                label=row['label'],\n",
    "                color=colors[idx]\n",
    "            )\n",
    "        \n",
    "        plt.xlabel('Atomic Action Length', fontsize=12)\n",
    "        plt.ylabel('Ratio', fontsize=12)\n",
    "        plt.title('Looped Atomic Action Length Distribution (All Experiments)', fontsize=14)\n",
    "        plt.xticks(all_lengths)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No looped atomic actions found in any experiment\")\n",
    "else:\n",
    "    print(\"No experiments to plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0690f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = 'loop_unit_len_stats_data.json'\n",
    "# with open(output_file, 'w', encoding='utf-8') as f:\n",
    "#     import json\n",
    "#     json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "# print(f\"Data exported to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
