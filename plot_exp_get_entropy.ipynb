{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c87ef09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ef46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import numpy as np\n",
    "from utils.analysis_files.analysis import plot_metric_bar, plot_metric_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results(base_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load result.json files from all experiment subdirectories under the specified base directory,\n",
    "    and merge them into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    all_results_data = []\n",
    "\n",
    "    if not os.path.isdir(base_dir):\n",
    "        print(f\"Error: Base directory '{base_dir}' does not exist.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Iterate through all entries in base directory\n",
    "    for exp_folder_name in os.listdir(base_dir):\n",
    "        exp_path = os.path.join(base_dir, exp_folder_name)\n",
    "\n",
    "        # Ensure it is a directory\n",
    "        if os.path.isdir(exp_path):\n",
    "            result_file_path = os.path.join(exp_path, \"result.json\")\n",
    "\n",
    "            # Check if result.json exists\n",
    "            if os.path.exists(result_file_path):\n",
    "                try:\n",
    "                    with open(result_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        result_data = json.load(f)\n",
    "                        # Add experiment folder name as a column for identification\n",
    "                        result_data[\"experiment\"] = exp_folder_name\n",
    "                        all_results_data.append(result_data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Warning: Unable to parse JSON in file {result_file_path}.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Error reading file {result_file_path}: {e}\")\n",
    "\n",
    "    if not all_results_data:\n",
    "        print(\"No 'result.json' files found or processed.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    results_df = pd.DataFrame(all_results_data)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"webshop\"\n",
    "# Set root directory for all experiment results\n",
    "all_exp_base_dir = f\"./res_fake/{task}\"\n",
    "\n",
    "# Load all experiment results into DataFrame\n",
    "df_experiments = load_all_results(all_exp_base_dir)\n",
    "\n",
    "# Display first few rows of DataFrame for inspection\n",
    "if not df_experiments.empty:\n",
    "    print(f\"Successfully loaded results from {len(df_experiments)} experiments.\")\n",
    "    # display(df_experiments.head())\n",
    "else:\n",
    "    print(\"Failed to load any experiment results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_criteria = {\n",
    "    # 'model_name': 'Qwen3-30B-A3B',\n",
    "    # \"enable_thinking\": False,\n",
    "    \"state\": \"env\",\n",
    "    'chat_format': 'user_assistant_format',\n",
    "    # \"alfworld_mode\": \"eval_in_distribution\",\n",
    "    'history_has_cot': True,\n",
    "    \"stop_by_self\": False,\n",
    "    \"offer_feedback\": True,\n",
    "    \"prompt_example\": \"fewshot\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9958052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Filter DataFrame based on criteria ---\n",
    "if selection_criteria:\n",
    "    # Start from base DataFrame\n",
    "    query_str = \" & \".join(\n",
    "        [f\"`{k}` == {repr(v)}\" for k, v in selection_criteria.items()]\n",
    "    )\n",
    "    selected_df = df_experiments.query(query_str)\n",
    "else:\n",
    "    # If no filter criteria, select all experiments\n",
    "    selected_df = df_experiments\n",
    "model_order = [\n",
    "    'Qwen3-4B',\n",
    "    'Qwen3-30B-A3B',\n",
    "    'Llama3-8B',\n",
    "    'Llama3-70B',\n",
    "    'Llama-3.1-8B',\n",
    "    'Llama-3.3-70B',\n",
    "    'Glm-9B-Chat',\n",
    "    'Glm4-9B-Chat',\n",
    "    \"GLM-4-32B-0414\",\n",
    "    'Mistral-7B-Instruct-v0.3',\n",
    "    'Ministral-3-14B-Instruct-2512',\n",
    "    'phi-4',\n",
    "    'deepseek-v3',\n",
    "    'deepseek-v3.2',\n",
    "    'gemini-2.5-flash',\n",
    "    'gemini-2.5-flash-nothinking',\n",
    "    'Phi-4-reasoning',\n",
    "    'gpt-oss-120b',\n",
    "    'deepseek-r1',\n",
    "    'gemini-2.5-pro',\n",
    "]\n",
    "# Create a mapping dictionary to map model names to sort indices\n",
    "model_order_map = {model: idx for idx, model in enumerate(model_order)}\n",
    "\n",
    "# Add a temporary column for sorting\n",
    "selected_df['model_sort_order'] = selected_df['model_name'].map(\n",
    "    lambda x: model_order_map.get(x, 999)  # Models not in list are placed last\n",
    ")\n",
    "sort_list = ['model_sort_order','chat_format','enable_thinking','history_has_cot',\"state\"]\n",
    "selected_df = selected_df.sort_values(by=sort_list, ascending=[True, True, True, True, False]).reset_index(drop=True)\n",
    "print(f\"Found {len(selected_df)} experiments matching the filter criteria.\")\n",
    "display(\n",
    "    selected_df[[\"model_name\",\"state\", \"chat_format\",\"enable_thinking\", \"history_has_cot\", \"pass_mean\", \"mean_loop_ratio_after_invalid_steps_stepnorm\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot_metric_line(\n",
    "#     selected_df,\n",
    "#     select_col=\"pass1_at_T\",\n",
    "#     xlabel=\"Number of Turns to Pass@1\",\n",
    "#     ylabel=\"pass@1\",\n",
    "#     title=\"pass@1 at T(urns)\",\n",
    "#     selection_criteria=selection_criteria,\n",
    "# )\n",
    "# plot_metric_line(\n",
    "#     selected_df,\n",
    "#     select_col=\"passk_at_T\",\n",
    "#     xlabel=\"Number of Turns to Pass@k\",\n",
    "#     ylabel=\"pass@k\",\n",
    "#     title=\"pass@k at T(urns)\",\n",
    "#     selection_criteria=selection_criteria,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Entropy Data and Save to JSON\n",
    "label_mapping = {\n",
    "    'Qwen3-4b\\n-enable_thinking=F': 'Qwen3-4B',\n",
    "    'Qwen3-4B\\n-enable_thinking=F': 'Qwen3-4B',\n",
    "    'Qwen3-4B\\n-enable_thinking=T': 'Qwen3-4B-Thinking',\n",
    "    'Qwen3-30B-A3B\\n-enable_thinking=F': 'Qwen3-30B-A3B',\n",
    "    'Qwen3-30B-A3B\\n-enable_thinking=T': 'Qwen3-30B-A3B-Thinking',\n",
    "    'Llama3-8B\\n-enable_thinking=F': 'Llama3-8B',\n",
    "    'Llama3-70B\\n-enable_thinking=F': 'Llama3-70B',\n",
    "    'Llama-3.1-8B\\n-enable_thinking=F': 'Llama-3.1-8B',\n",
    "    'Llama-3.3-70B\\n-enable_thinking=F': 'Llama-3.3-70B',\n",
    "    'Glm-9B-Chat\\n-enable_thinking=F': 'Glm-4-9B-Chat',\n",
    "    'Glm4-9B-Chat\\n-enable_thinking=F': 'Glm-4-9B-Chat',\n",
    "    \"GLM-4-32B-0414\\n-enable_thinking=F\": \"GLM-4-32B-0414\",\n",
    "    'Mistral-7B-Instruct-v0.3\\n-enable_thinking=F': 'Mistral-7B',\n",
    "    'Ministral-3-14B-Instruct-2512\\n-enable_thinking=F': 'Ministral-3-14B-Instruct-2512',\n",
    "    'phi-4\\n-enable_thinking=F': 'Phi-4',\n",
    "    'deepseek-v3\\n-enable_thinking=F': 'Deepseek-v3',\n",
    "    'deepseek-v3.2\\n-enable_thinking=F': 'Deepseek-v3.2',\n",
    "    'gemini-2.5-flash\\n-enable_thinking=F': 'Gemini2.5-Flash',\n",
    "    'gemini-2.5-flash-nothinking\\n-enable_thinking=F': 'Gemini2.5-Flash',\n",
    "    'Phi-4-reasoning\\n-enable_thinking=T': 'Phi-4-Reasoning',\n",
    "    'gpt-oss-120b\\n-enable_thinking=T': 'GPT-OSS-120B',\n",
    "    'deepseek-r1\\n-enable_thinking=T': 'Deepseek-R1',\n",
    "    'gemini-2.5-pro\\n-enable_thinking=T': 'Gemini2.5-Pro',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1eeea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.analysis_files.analysis import get_config_label\n",
    "exclude_keys = set(selection_criteria.keys()) if selection_criteria else set()\n",
    "entropy = []\n",
    "for idx, row in selected_df.iterrows():\n",
    "    label = get_config_label(row, exclude_keys=exclude_keys)\n",
    "    label = label_mapping.get(label, label)\n",
    "    pass_1_at_t = row[\"pass1_at_T\"]\n",
    "    entropy.append({\n",
    "        \"model\": label,\n",
    "        \"pass_1_at_t\": pass_1_at_t,\n",
    "    })\n",
    "with open(f\"{task}_loop_pass_1_at_t.json\", 'w') as f:\n",
    "    json.dump(entropy, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28dedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Entropy Data and Save to JSON\n",
    "from utils.analysis_files.analysis import get_config_label\n",
    "exclude_keys = set(selection_criteria.keys()) if selection_criteria else set()\n",
    "entropy = []\n",
    "for idx, row in selected_df.iterrows():\n",
    "    label = get_config_label(row, exclude_keys=exclude_keys)\n",
    "    label = label_mapping.get(label, label)\n",
    "    mean_normal_step_action_entropy = row[\"mean_normal_step_action_entropy\"]\n",
    "    mean_loop_step_action_entropy = row[\"mean_loop_step_action_entropy\"]\n",
    "    mean_normal_step_analysis_entropy = row[\"mean_normal_step_analysis_entropy\"]\n",
    "    mean_loop_step_analysis_entropy = row[\"mean_loop_step_analysis_entropy\"]\n",
    "    entropy.append({\n",
    "        \"model\": label,\n",
    "        \"mean_normal_step_action_entropy\": mean_normal_step_action_entropy,\n",
    "        \"mean_loop_step_action_entropy\": mean_loop_step_action_entropy,\n",
    "        \"mean_normal_step_analysis_entropy\": mean_normal_step_analysis_entropy,\n",
    "        \"mean_loop_step_analysis_entropy\": mean_loop_step_analysis_entropy,\n",
    "    })\n",
    "with open(f'{task}_loop_entropy.json', 'w') as f:\n",
    "    json.dump(entropy, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
